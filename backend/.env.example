# ============================================
# Moffitt Agentic RAG - Backend Configuration
# ============================================

# API Authentication
# ------------------
API_KEY=dev_api_key

# LLM Provider Settings
# ----------------------
# Options: openai, groq, ollama
LLM_PROVIDER=groq

# Groq Settings (Free tier available)
# Get your key at: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# OpenAI Settings (Paid)
# Get your key at: https://platform.openai.com/account/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Euron Settings (Optional)
EURON_API_KEY=your_euron_api_key_here
EURON_MODEL=gpt-4.1-nano

# Ollama Settings (For local deployment)
LLM_MODEL_NAME=llama3
OLLAMA_BASE_URL=http://localhost:11434

# Embedding Model
# ---------------
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# LangSmith Configuration (Optional - for observability & evaluation)
# --------------------------------------------------------------------
# Get your API key at: https://smith.langchain.com/settings
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=moffitt-agentic-rag-dev
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Data Directories (Relative to backend/)
# ----------------------------------------
VECTOR_DB_DIR=../data/vector_db
PROCESSED_DATA_DIR=../data/processed
MARKDOWN_DATA_DIR=../data/markdown

# Network Settings
# ----------------
API_HOST=localhost
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# ============================================
# QUICK START (Local Development):
# 1. Copy this file to .env in the backend/ directory
# 2. Replace 'your_groq_api_key_here' with your actual Groq API key
# 3. Run: python validate_env.py (to check setup)
# 4. Run: uvicorn main:app --reload
# ============================================