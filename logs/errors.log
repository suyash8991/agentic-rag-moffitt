2025-10-23 17:30:33,910 [ERROR] moffitt_rag.agents.limited_call (limited_call.py:126): Error during agent execution: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
None
2025-10-23 17:30:33,914 [ERROR] moffitt_rag.errors (logging.py:392): Error executing query 'who is Theresa Boyle?': Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
(<class 'openai.BadRequestError'>, BadRequestError('Error code: 400 - {\'error\': {\'message\': "Unsupported value: \'temperature\' does not support 0.2 with this model. Only the default (1) value is supported.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': \'unsupported_value\'}}'), <traceback object at 0x00000210160D7A80>)
Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 146, in invoke_agent
    result = agent.invoke({"input": query})
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 69, in invoke
    result = self._run_with_limits(input_dict, **kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 113, in _run_with_limits
    result = self.agent_executor.invoke(inputs, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 104, in patched_take_next_step
    return original_take_next_step(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 455, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_openai\chat_models\base.py", line 1123, in _stream
    response = self.client.create(**payload)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-10-23 17:30:33,928 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:162): Agent invocation error: BadRequestError: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
None
2025-10-23 17:30:33,929 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:163): Traceback: Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 146, in invoke_agent
    result = agent.invoke({"input": query})
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 69, in invoke
    result = self._run_with_limits(input_dict, **kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 113, in _run_with_limits
    result = self.agent_executor.invoke(inputs, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 104, in patched_take_next_step
    return original_take_next_step(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 455, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_openai\chat_models\base.py", line 1123, in _stream
    response = self.client.create(**payload)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}

None
2025-10-23 17:32:50,809 [ERROR] moffitt_rag.agents.agent (agent.py:318): Unhandled error in create_researcher_agent: NameError: name 'temperature' is not defined
None
2025-10-23 17:32:50,810 [ERROR] moffitt_rag.agents.agent (agent.py:319): Traceback: Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\agent.py", line 182, in create_researcher_agent
    "temperature": temperature,
NameError: name 'temperature' is not defined

None
2025-10-23 17:32:50,811 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:127): Agent creation error: NameError: name 'temperature' is not defined
None
2025-10-23 17:32:50,811 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:128): Traceback: Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 115, in get_agent
    agent = create_researcher_agent()
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\agent.py", line 182, in create_researcher_agent
    "temperature": temperature,
NameError: name 'temperature' is not defined

None
2025-10-23 17:32:50,813 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:176): Agent initialization error: NameError: name 'temperature' is not defined
None
2025-10-23 17:32:50,815 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:177): Traceback: Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 136, in invoke_agent
    agent = get_agent()
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\streamlit\runtime\caching\cache_utils.py", line 227, in __call__
    return self._get_or_create_cached_value(args, kwargs, spinner_message)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\streamlit\runtime\caching\cache_utils.py", line 269, in _get_or_create_cached_value
    return self._handle_cache_miss(cache, value_key, func_args, func_kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\streamlit\runtime\caching\cache_utils.py", line 328, in _handle_cache_miss
    computed_value = self._info.func(*func_args, **func_kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 115, in get_agent
    agent = create_researcher_agent()
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\agent.py", line 182, in create_researcher_agent
    "temperature": temperature,
NameError: name 'temperature' is not defined

None
2025-10-23 17:33:32,874 [ERROR] moffitt_rag.agents.limited_call (limited_call.py:126): Error during agent execution: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
None
2025-10-23 17:33:32,875 [ERROR] moffitt_rag.errors (logging.py:392): Error executing query 'who is Theresa Boyle?': Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
(<class 'openai.BadRequestError'>, BadRequestError('Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'stop\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'stop\', \'code\': \'unsupported_parameter\'}}'), <traceback object at 0x0000029447205F40>)
Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 146, in invoke_agent
    result = agent.invoke({"input": query})
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 69, in invoke
    result = self._run_with_limits(input_dict, **kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 113, in _run_with_limits
    result = self.agent_executor.invoke(inputs, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 104, in patched_take_next_step
    return original_take_next_step(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 455, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_openai\chat_models\base.py", line 1123, in _stream
    response = self.client.create(**payload)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
2025-10-23 17:33:32,886 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:162): Agent invocation error: BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
None
2025-10-23 17:33:32,888 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:163): Traceback: Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 146, in invoke_agent
    result = agent.invoke({"input": query})
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 69, in invoke
    result = self._run_with_limits(input_dict, **kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 113, in _run_with_limits
    result = self.agent_executor.invoke(inputs, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 104, in patched_take_next_step
    return original_take_next_step(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 455, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_openai\chat_models\base.py", line 1123, in _stream
    response = self.client.create(**payload)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}

None
2025-10-23 19:13:00,232 [ERROR] moffitt_rag.agents.limited_call (limited_call.py:126): Error during agent execution: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
None
2025-10-23 19:13:00,233 [ERROR] moffitt_rag.errors (logging.py:392): Error executing query 'who is Theresa Boyle?': Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
(<class 'openai.BadRequestError'>, BadRequestError('Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'stop\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'stop\', \'code\': \'unsupported_parameter\'}}'), <traceback object at 0x0000026936EE2A80>)
Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 146, in invoke_agent
    result = agent.invoke({"input": query})
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 69, in invoke
    result = self._run_with_limits(input_dict, **kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 113, in _run_with_limits
    result = self.agent_executor.invoke(inputs, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 104, in patched_take_next_step
    return original_take_next_step(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 455, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_openai\chat_models\base.py", line 1123, in _stream
    response = self.client.create(**payload)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
2025-10-23 19:13:00,256 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:162): Agent invocation error: BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
None
2025-10-23 19:13:00,257 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:163): Traceback: Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 146, in invoke_agent
    result = agent.invoke({"input": query})
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 69, in invoke
    result = self._run_with_limits(input_dict, **kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 113, in _run_with_limits
    result = self.agent_executor.invoke(inputs, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 104, in patched_take_next_step
    return original_take_next_step(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 455, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_openai\chat_models\base.py", line 1123, in _stream
    response = self.client.create(**payload)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}

None
2025-10-23 19:15:58,894 [ERROR] moffitt_rag.agents.limited_call (limited_call.py:126): Error during agent execution: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
None
2025-10-23 19:15:58,895 [ERROR] moffitt_rag.errors (logging.py:392): Error executing query 'who is Theresa Boyle?': Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
(<class 'openai.BadRequestError'>, BadRequestError('Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'stop\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'stop\', \'code\': \'unsupported_parameter\'}}'), <traceback object at 0x0000022CF09F87C0>)
Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 146, in invoke_agent
    result = agent.invoke({"input": query})
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 69, in invoke
    result = self._run_with_limits(input_dict, **kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 113, in _run_with_limits
    result = self.agent_executor.invoke(inputs, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 104, in patched_take_next_step
    return original_take_next_step(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 455, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_openai\chat_models\base.py", line 1123, in _stream
    response = self.client.create(**payload)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
2025-10-23 19:15:58,905 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:162): Agent invocation error: BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}
None
2025-10-23 19:15:58,907 [ERROR] moffitt_rag.streamlit.components.chat (chat.py:163): Traceback: Traceback (most recent call last):
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\streamlit\components\chat.py", line 146, in invoke_agent
    result = agent.invoke({"input": query})
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 69, in invoke
    result = self._run_with_limits(input_dict, **kwargs)
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 113, in _run_with_limits
    result = self.agent_executor.invoke(inputs, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
  File "C:\Coding\Projects\moffitt-agentic-rag\src\moffitt_rag\agents\limited_call.py", line 104, in patched_take_next_step
    return original_take_next_step(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain\agents\agent.py", line 455, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3650, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3636, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 2372, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 3595, in _transform
    yield from final_pipeline
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1571, in transform
    for ichunk in input:
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 5927, in transform
    yield from self.bound.transform(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\runnables\base.py", line 1589, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\langchain_openai\chat_models\base.py", line 1123, in _stream
    response = self.client.create(**payload)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\suyas\miniconda3\envs\moffitt-agentic-rag\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'stop' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'stop', 'code': 'unsupported_parameter'}}

None
